\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.2}{\ignorespaces An example of a Vehicle-in-the-Loop (VitL) setup. A real car on a test track connected to a high-fidelity simulator like CARLA that generates virtual traffic and sensor data.~\blx@tocontentsinit {0}\cite {DSR22}}}{7}{figure.2.2}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces The foundational concept of a Digital Twin, illustrating the three core components: the physical entity, the virtual model and the bi-directional data connection that links them~\blx@tocontentsinit {0}\cite {Grieves2017, Leng2021}.~\blx@tocontentsinit {0}\cite {Grieves15}}}{9}{figure.2.3}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces The Reality-Virtuality Continuum, illustrating the spectrum from a real environment to a completely virtual one.~\blx@tocontentsinit {0}\cite {Walker2023}}}{11}{figure.2.5}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces The ROS~2 publish-subscribe model. Node A publishes messages onto a central topic and any number of subscriber nodes (B and C) may receive that data without direct knowledge of the publisher.}}{12}{figure.2.6}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces A simplified example of a ROS~2 transform tree (tf tree). The library maintains the hierarchical relationships so that a program can easily determine the transform from the \texttt {camera\_link} to the \texttt {world} frame, for instance.}}{13}{figure.2.7}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces The physical setup of the VERA platform: A projector and tracking system are mounted on a frame above the test area.~\blx@tocontentsinit {0}\cite {Geh24}}}{14}{figure.2.8}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces The EMAROs robot is the robotic platform used in the testbed, equipped with a modular sensor suite and running ROS~2.~\blx@tocontentsinit {0}\cite {Geh24}}}{15}{figure.2.9}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces The original VERA used point clouds~\blx@tocontentsinit {0}\cite {Geh24}, while the current iteration uses ArUco markers for pose estimation~\blx@tocontentsinit {0}\cite {JuliaBA}.}}{16}{figure.2.10}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces Original VERA visualization via Pygame, showing a projection of the robot's path and virtual obstacles onto the floor.~\blx@tocontentsinit {0}\cite {Geh24}}}{17}{figure.2.11}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.2}{\ignorespaces The Hardware and Software Topology of the Mixed Reality Environment.}}{31}{figure.4.2}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Software Component Architecture. Unity scripts act as ROS~2 nodes, publishing sensor data and subscribing to control commands using ROS~2 topics.}}{33}{figure.4.3}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces The robot attachment logic. (a) The robot approaches the target object.\\ (b) The object is kinematically coupled to the robot chassis.}}{37}{figure.4.4}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces Demonstration of dynamic surface modification. The robot uses the \texttt {TrackPainter.cs} component to modify the floor texture in real-time based on its trajectory, creating a persistent black trail.}}{38}{figure.4.5}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces Visualization of the LiDAR simulation in the editor. Red debug lines indicate raycasts that did not hit an obstacle within range, while yellow debug lines indicate valid hits registered by the physics engine.}}{39}{figure.4.6}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces The Augmented Telemetry interface. A billboard displays system stats, while the \texttt {RosImageToMaterial.cs} component projects the live OpenCV debug feed onto a plane attached to the robot, visualizing the internal state of the perception stack.}}{43}{figure.4.7}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces Debug view of the Smart Farming agent during edge following. The processor identifies the boundary between the field (left) and the path (right). The green line represents the detected edge used for navigation, while the red dot indicates the centroid used to compute the lateral and angular errors displayed in the overlay.}}{47}{figure.4.8}%
\contentsline {figure}{\numberline {4.9}{\ignorespaces Debug view of the Logistics agent. The processor identifies a red transport box in its ROI (green) and calculates the centroid (red dot).}}{49}{figure.4.9}%
\contentsline {figure}{\numberline {4.10}{\ignorespaces Debug view of the Line Follower. The system isolates the user-drawn path and fits a vector (blue line) to calculate lateral and angular errors for the PID controller.}}{51}{figure.4.10}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
