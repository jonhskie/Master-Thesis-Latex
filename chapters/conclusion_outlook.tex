\chapter{Conclusion and Outlook}
\label{ch:conclusion_outlook}

Mobile robots have become essential in modern industry, agriculture, and research, increasing the need for thorough development and validation methods. Developing these systems often requires a mixed approach, combining the safety of virtual simulation for quick prototyping with the accuracy of physical experiments for final validation. However, virtual environments often cannot accurately model complex dynamics, such as sensor noise and friction. On the other hand, physical testing provides reliable data, but it is usually very expensive and less flexible. This limits the ability to test edge cases or change environments easily.

The Mixed Reality Environment created in this thesis tackles these challenges. It provides a shared workspace for simulation and physical testing. This setup supports a Robot-in-the-Loop platform, where a physical robot interacts with a synchronized virtual world. The system combines the Unity engine with the Robot Operating System 2. This setup allows the robot to see virtual objects as if they were real.

The system uses a Digital Twin to synchronize the physical robot with the simulation. An ArUco tracking system links the robot's position to the virtual environment for positional alignment. This setup enables the physical robot to interact with virtual obstacles. The simulation creates virtual sensors, such as LiDAR scans and camera feeds. This sensor data is sent back into the robot's perception system, enabling the navigation software to react to virtual objects as if they were real.

The system was evaluated using the Paint, Logistics, and Farm scenarios, which covered Line Following, Autonomous Logistics, and Smart Farming tasks. These cases demonstrated that the framework can manage various interactions, like changing surfaces or transporting objects. The successful execution of these diverse tasks validates the versatility of the architecture, demonstrating its capability to support everything from fundamental navigation to complex, multi-stage behaviors. This highlights its usefulness as a testbed for robotic applications.

The system's modular design allows for future improvements. Future efforts should aim to enhance physical realism by enabling the physical robot to react to virtual resistance. Right now, the digital twin acts as a kinematic body that applies infinite force to virtual objects. Implementing feedback would allow the simulation to limit the robot's motor torque or speed during collisions or resistance, mimicking the resistance of heavy obstacles, high-friction surfaces or inclines.

The digital twin could be expanded with virtual extensions modules for more complex applications. Virtual tools like robotic arms or agricultural sprayers could connect to the digital twin and be controlled through ROS 2. This would allow researchers to test control software for hardware that isn't physically present and speed up the design of new tools.

The system could also expand to support multi-robot setups and enhanced visualization capabilities. Adjusting the framework to support multiple real and virtual robots would help validate collaborative algorithms. This would allow for the formation of hybrid swarms, enabling a small number of physical robots to coordinate with a large fleet of virtual agents. Additionally, using Passthrough Mixed Reality headsets would expand the visualization beyond the floor plane. Unlike the current projection system, this would enable the display of three-dimensional structures and vertical information, providing a more immersive and detailed feedback loop for the operator.

In conclusion, this thesis presents a Mixed Reality Environment that effectively bridges the gap between simulation and physical testing. By integrating modern game engine technology with ROS 2, the system enables bidirectional interaction between real robots and virtual elements through a synchronized Digital Twin. Furthermore, the system enhances situational awareness by displaying diagnostic data on status billboards and projecting live camera feeds. The evaluation confirms that this architecture provides a stable and versatile platform for validating robotic behaviors. Its modular design lays the foundation for future enhancements, supporting the development of increasingly complex Robot-in-the-Loop applications.