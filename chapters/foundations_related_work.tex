\chapter{Background and Related Work}
\label{chap:background}
Einführung in das kapitel \cite{NOT FINAL}
 \section{Robot-in-the-Loop-Testing}
\label{sec:RitL}
The validation and verification of modern Robotic and Autonomous Systems (RAS) is a significant challenge due to their complexity \cite{AMV23}. This is because they integrate software, mechanical, and electrical engineering all at once. \cite{AMV23}. A central problem is ensuring that the software and hardware work together seamlessly, especially when testing both simultaneously \cite{AMV23}. The X-in-the-Loop (XitL) simulation paradigm addresses this challenge \cite{Brayanov2019}. It offers a way to combine the flexibility of software simulation with the realism of physical experiments \cite{Brayanov2019}.

A foundational XitL method is Hardware-in-the-Loop (HIL) simulation, which is a technique for testing mechatronic systems \cite{Mihalic2022, Brayanov2019}. The main principle of HIL is creating a closed loop between the real hardware that is being tested and a simulation that represents the rest of the system or its operational environment \cite{Mihalic2022}. This setup effectively tricks the hardware into behaving as if it were operating in a real system, which allows for testing across a wide range of virtual scenarios \cite{Brayanov2019}. The main reason for using HIL is to shorten development cycles and prevent costly or dangerous failures by making exhaustive testing possible before the system is actually completely implemented \cite{Mihalic2022}.This is why HIL is essential in industries like automotive, aerospace, and robotics, where real-world testing can be too expensive, dangerous, or even impossible \cite{Brayanov2019}.

Robot-in-the-Loop (RitL) \cite{Mihalic2022} simulation extends the Hardware-in-the-Loop (HIL) concept. Instead of just a component, the hardware under test is a complete robotic system, such as an uncrewed vehicle \cite{Mihalic2022}. RitL replaces components of an pure simulated setup with the actual robot, increasing the realism of testing \cite{Hu05}. As illustrated in Figure \ref{fig:ritl_concept}, a typical RitL configuration has the robot's real actuators operating in the physical world, while while its sensors interact with a simulated environment instead (Hu05, Mihalic2022). This creates a hybrid setup where, for example, the robot might use virtual sensors to see objects in the simulation but use its real motors to move physically \cite{Hu05}. To keep the physical and virtual worlds synchronized, the real robot often has a virtual counterpart in the simulation which state is updated as the physical robot acts and moves \cite{Hu05}.

\begin{figure}[h]
\centering
% \includegraphics[width=0.8\textwidth]{path/to/ritl_concept_diagram.png}
\caption{Conceptual diagram of a Robot-in-the-Loop (RitL) simulation, showing the real robot interacting with a virtual environment. The real robot's actions affect its virtual counterpart, and the virtual environment provides sensor data back to the real robot.}
\label{fig:ritl_concept}
\end{figure}

The key advantage of RitL is that it allows repeatable testing of high level software, like navigation algorithms, while still using the dynamics of real hardware \cite{Mihalic2022}. This approach provides a safe and practical alternative to full physical testbeds and avoiding their cost, complexity, and risk \cite{Mihalic2022}. As a result, RitL becomes an vital tool for safely evaluating system performance in the lab \cite{Hu05, Mihalic2022}. This is especially important when safety is at stake or when working on projects that are difficult to reproduce, like Mars rover missions or large scale robot swarms \cite{Hu05, Mihalic2022}.

The RitL paradigm has been widely applied to validate complex autonomous systems, particularly in the automotive field using Vehicle-in-the-Loop (VitL) testing. For example, the Dynamic Vehicle-in-the-Loop (DynViL) architecture integrates a real test vehicle with the high-fidelity CARLA simulator, which operates on the Unreal Engine \cite{DSR22}. As shown in Figure \ref{fig:vitl_setup}, this approach allows a vehicle on an empty track to be stimulated by sensor data from a virtual world \cite{DSR22}. This enables the safe and repeatable testing of automated driving functions in scenarios that would be dangerous to replicate physically \cite{DSR22}. A similar Vehicle-in-Virtual-Environment (VVE) method also uses CARLA and the Unreal Engine to create a closed loop where the real vehicle's motion is tracked and reflected in the virtual world, allowing its control systems to react to simulated events \cite{Cao2023}.

\begin{figure}[h]
\centering
% \includegraphics[width=0.9\textwidth]{path/to/vitl_setup_diagram.png}
\caption{An example of a Vehicle-in-the-Loop (VitL) setup, illustrating a real car on a test track connected to a high-fidelity simulator like CARLA that generates virtual traffic and sensor data. Adapted from Drechsler et al. (2022) and Cao et al. (2023).}
\label{fig:vitl_setup}
\end{figure}

These examples show a trend towards using game engine based simulators to evaluate autonomous vehicles. This approach sits between pure software simulation, which often lacks vehicle dynamics fidelity, and physical testing, where safety and consistency can pose challenges \cite{Cao2023}. Some systems even stimulate the vehicle’s actual sensors. For instance, the Radar Target Simulator (RTS) can feed artificial radar echoes from a virtual scene to the vehicle's real radar sensor \cite{Diewald2021}. This allows for end-to-end validation of the entire perception and control pipeline \cite{Diewald2021}.

The X-in-the-Loop approach is not limited to a single domain, it is used in a variety of fields. In marine robotics, a VIL framework was developed to test the long term autonomy of a robot swarm. In this system, a Autonomous Surface Vehicle (ASV) interacts with many simulated underwater sensor nodes to validate complex cooperative behaviors without the high logistical cost of deploying a full swarm \cite{Babic2020}. In the aerospace domain, the RFlySim platform uses an FPGA-based HIL system to create a high fidelity simulation for testing UAV autopilot systems in a lab, which reduces the need for expensive and risky outdoor flights \cite{Dai2021}.

These approaches continue progressing toward deeper integration. This includes the introduction of Scenario-in-the-Loop (SciL) frameworks that aim to completely blur the lines between real and virtual testing \cite{Szalay2021}. These systems rely on creating comprehensive digital twins of the entire test environment and combining real and virtual components to run complex, mixed reality test scenarios \cite{Szalay2021}.

\section{Digital Twins}
\label{sec:DT}
A key concept in many modern X-in-the-Loop frameworks is the Digital Twin (DT). The DT serves as the virtual counterpart to a physical system, acting as a virtual copy that allows real-time monitoring and simulation \cite{AA23}. The core idea is to create a digital information model of a physical system that stays linked to it throughout its entire lifecycle \cite{Grieves2017}.

This model, first called the Information Mirroring Model, has three components: the physical product, its corresponding virtual model, and the data connection that links them \cite{Grieves2017, AA23}. A conceptual diagram of this structure is shown in Figure \ref{fig:dt_concept}. The virtual model is more than a simple geometric shape, it is often a complex simulation that can model a system's mechanical, electrical, and software properties \cite{Leng2021}. The data connection is bi-directional, allowing sensor data to flow from the real world to update the virtual model. In turn, the virtual model can send commands back to control or optimize the physical system \cite{Grieves2017, Leng2021}. This continuous, synchronized data exchange is the defining feature of a Digital Twin \cite{AA23}.

\begin{figure}[h]
\centering
% \includegraphics[width=0.8\textwidth]{path/to/dt_concept_diagram.png}
\caption{The foundational concept of a Digital Twin, illustrating the three core components: the physical entity, the virtual model, and the bi-directional data connection that links them. Adapted from Grieves et al. (2017).}
\label{fig:dt_concept}
\end{figure}

In robotics, Digital Twins are often built using specialized simulation software. The Robot Operating System (ROS) typically acts as the middleware connecting the virtual simulation to the physical hardware. For instance, Stączek et al. used the Gazebo simulator with ROS to create a DT of a factory floor, which they used to test and optimize the navigation algorithms of a mobile robot in narrow corridors \cite{Staczek2021}. A similar approach was taken by R. Singh et al., who developed a DT of a greenhouse in Gazebo to validate a deep learning-based harvesting robot \cite{Singh2024a}. Other simulators like CoppeliaSim and Webots are also common. Magrin et al. used CoppeliaSim and ROS to create a DT as a learning tool for mobile robot design \cite{Magrin2021}, while Marques et al. used Webots for an Automated Guided Vehicle (AGV), synchronizing it via an OPC-UA server \cite{Marques2024}. These examples show a common method of using traditional simulators to model robot kinematics and sensor feedback for closed-loop testing.

More recently, modern game engines have become a popular choice for creating Digital Twins, as they offer more realistic graphics and physics. The Unity game engine, in particular, is used to build powerful, performant, and visually rich virtual environments. This can be seen in Figure \ref{fig:dt_environments}. For example, Pérez et al. used Unity3D to develop a DT of a multi-robot cell that included an immersive Virtual Reality (VR) interface for virtual commissioning and operator training \cite{Perez2020}.

\begin{figure}[h]
\centering
% \includegraphics[width=0.9\textwidth]{path/to/dt_environments_comparison.png}
\caption{A comparison of robotic Digital Twin environments, showing a typical view from a traditional simulator (left) versus a high-fidelity visualization from a modern game engine like Unity (right).}
\label{fig:dt_environments}
\end{figure}

The technical capabilities of these engines are also a key factor. Yang et al. used Unity and its integrated NVIDIA PhysX engine to simulate the complex physics of a UAV. They also demonstrated how to create virtual sensors, such as a LiDAR, directly within the game engine using its raycasting API \cite{Yang2020}. The performance and reliability of these game engine-based frameworks have also been a focus of research. Kwon et al. developed a safety-critical DT in Unity and ROS 2, achieving a low data-transmission latency of just 13 ms for predicting collisions \cite{Kwon2025}. Similarly, M. Singh et al. created a Unity and ROS-based DT and conducted extensive performance validation, reporting a communication latency of 77.67 ms and a positional accuracy of 99.99\% \cite{Singh2024b}.

\section{Mixed Reality}
\label{sec:MR}
Beyond the testing paradigm and the digital twin, the way a user interacts with the system is another critical part of a modern robotics framework. Virtual, Augmented, and Mixed Reality (VAM) have become promising technologies for improving the information exchange between humans and robots \cite{Walker2023}. In robotics, Augmented Reality (AR) is an especially powerful tool for enhancing Human-Robot Interaction (HRI) by integrating 3D virtual objects into a real-world environment in real-time \cite{MV20}.

The relationship between these technologies is formally described by the foundational "Reality-Virtuality (RV) Continuum" concept, first introduced by Milgram and Kishino \cite{MK94, Skarbez2021, MV20}. As illustrated in Figure \ref{fig:rv_continuum}, this continuum is a scale that is anchored by a purely real environment at one end and a completely virtual one at the other \cite{MK94, Skarbez2021, MV20}.

\begin{figure}[h]
\centering
% \includegraphics[width=0.9\textwidth]{path/to/rv_continuum.png} % Placeholder for the image
\caption{The Reality-Virtuality Continuum, illustrating the spectrum from a real environment to a completely virtual one. Mixed Reality (MR) encompasses both Augmented Reality (AR) and Augmented Virtuality (AV). Adapted from Milgram \& Kishino (1994) \cite{MK94} and Walker et al. (2023) \cite{Walker2023}.}
\label{fig:rv_continuum}
\end{figure}

A conventional Virtual Reality (VR) environment represents the continuum's virtual endpoint. In VR, the user is totally immersed in and can interact with a completely synthetic world \cite{MK94}. This approach is very useful for HRI research, as it allows for testing interactions with virtual robots in scenarios that might be unsafe or too expensive for physical hardware \cite{Walker2023}. The general term Mixed Reality (MR) describes the entire spectrum between the two extremes, where real and virtual worlds are merged within a single display \cite{MK94}. MR is made up of two main categories: Augmented Reality (AR) and Augmented Virtuality (AV) \cite{MK94, MV20}. AR involves augmenting a real environment with virtual objects \cite{MK94}. This allows HRI researchers to place a robot's 3D data and intentions directly into the user's physical space \cite{Walker2023}. The opposite is Augmented Virtuality (AV), where a primarily virtual world is enhanced with elements from the real world, like live video feeds \cite{MK94}.

\section{The VERA Framework and EMARO}

\section{Comparison of Simulation Engines?}