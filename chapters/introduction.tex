\chapter{Introduction} \label{chap:introduction}

According to Araujo et al. \cite{AMV23}, Robotic and Autonomous Systems (RAS) are characterized by a rich integration of multiple disciplines, including control engineering and robotics, mechanical engineering, electronics, and software engineering. The validation and verification of these systems require a non-trivial extension of traditional testing methods to address their inherent multi-disciplinary nature. For researchers and practitioners, particularly those in the software testing community, adapting existing techniques for RAS presents a significant challenge. This has resulted in a sizeable body of literature dedicated to proposing and evaluating different testing techniques and processes, highlighting the critical need to establish structured methods for ensuring the reliability of these complex systems.

This validation challenge highlights a fundamental tension between two traditional testing paradigms: virtual-only simulation and full-scale physical experimentation. Simulation is a cornerstone of robotic development, offering a way to test control logic and experiment with system configurations before committing them to hardware \cite{Hu05}. However, a significant gap between the virtual and physical worlds emerges when simulation models are abandoned during the implementation phase. This transition often requires control logic to be rewritten, a process that risks introducing new faults \cite{Hu05}. Virtual models, by their nature, cannot perfectly represent every characteristic of a physical component \cite{Hu05}. Conversely, while testing with real hardware provides the highest fidelity and allows for controls to be refined based on real-world phenomena \cite{Hu05}, this approach has its own severe drawbacks. Conducting full-scale physical experiments can be prohibitively expensive and time-consuming \cite{Hu05}. Furthermore, for complex, large-scale cooperative systems, testing the entire system with all-real components may not even be feasible due to issues of complexity and scale \cite{Hu05}. As neither approach is fully sufficient on its own, there is a clear need for an intermediate, hybrid methodology that can connect the simulation-based study with real-system experimentation \cite{Hu05}.

To bridge this validation gap, hybrid paradigms such as Hardware-in-the-Loop-Simulation (HILS) have emerged, in which parts of a pure simulation are replaced with actual physical components \cite{Hu05}. This research focuses on a specific application of this concept known as "robot-in-the-loop" (RitL) simulation, a novel method that allows real robots and robot models to work together for system-wide measurement and test \cite{Hu05}. This paradigm provides the flexibility to experiment with real robots in a virtual environment, allowing them to be tested and evaluated even when a full physical environment is not available \cite{Hu05}. This hybrid interaction is enabled by a core enabling technology: the Digital Twin \cite{AA23}. A digital twin is a virtual copy of the physical thing that can monitor it in real time \cite{AA23}. Through connectivity and rapid processing, the digital twin is able to mirror the physical asset and synchronize data with it \cite{AA23}. To manage this complex hybrid test environment, Augmented Reality (AR) is increasingly utilized as a new medium for interaction and information exchange with autonomous systems, enhancing the efficiency of Human-Robot Interaction (HRI) \cite{MV20}. The powerful combination of RitL testing \cite{Hu05}, synchronized Digital Twins \cite{AA23}, and intuitive AR interfaces \cite{MV20} represents a state-of-the-art approach for developing and validating the next generation of complex robotic systems.

A system that integrates these concepts of digital twins, augmented reality (AR), and vehicle-in-the-loop testing is the "Virtual Environment for mobile Robotic Applications" (VERA) framework, which was designed to bridge the gap between simulation and real-world testing \cite{Geh24}. VERA provides a modular platform for creating, managing, and visualizing synchronized virtual environments, which are presented both in simulations and as real-world projections \cite{Geh24}. This master's thesis builds directly upon the foundation laid by this original framework.

While the VERA framework provided a promising conceptual foundation, its original implementation has several documented limitations that this thesis seeks to address \cite{Geh24}. A primary limitation was that its custom environment manager could not offer a full physics simulation, with the integration of enhanced physics noted as a direction for future work \cite{Geh24}. Furthermore, the 2D visualizer, based on Pygame, encountered performance degradation when handling a high number of dynamic objects; in scenarios with many updates, its capacity was exceeded, leading to delayed and incomplete visualizations \cite{Geh24}. Lastly, while AR-like projections were implemented, more immersive Virtual Reality (VR) interaction was not part of the original scope and was identified as a potential future extension \cite{Geh24}. Therefore, the central problem is that the original VERA framework, while conceptually promising, is technically constrained by its custom components, limiting its physical realism, performance scalability, and interaction capabilities.

To address these technical constraints, the primary objective of this thesis is to replace the custom simulation and visualization components of the VERA framework \cite{Geh24} with the Unity Engine \cite{Uni23}. This implementation will leverage the Unity Engine \cite{Uni23}, which was selected specifically for its advanced graphics, integrated physics, and native VR support, to overcome the previously identified constraints of the VERA system.

The core goal is to establish a high-fidelity, real-time digital twin \cite{AA23} of the EMAROS robot \cite{Geh24}, incorporating not only its model but also its live sensor data and physical properties, such as mass, inertia, and collision models. This digital twin will serve as the foundation for "robot-in-the-loop" \cite{Hu05} testing scenarios. Furthermore, this project will implement user interaction, moving beyond the original AR projections \cite{Geh24} to include Virtual Reality (VR) \cite{EM21} and desktop interfaces for scenario modification, robot control, and data visualization. This also includes reimplementing and enhancing VERA's AR floor projection feature by utilizing Unity's advanced rendering tools to improve visual quality and system capabilities \cite{Uni23}.

\cite{NOT FINAL}The remainder of this thesis is structured as follows: Chapter 2 reviews the foundational concepts of Robot-in-the-Loop testing, Digital Twins, and Mixed Reality, and includes a detailed review of the original VERA framework. Chapter 3 defines the new system requirements based on VERA's limitations. Chapter 4 details the implementation of the new architecture, including the Unity/ROS 2 integration, the EMAROS digital twin and the implemented scenarios. Chapter 5 presents the evaluation and discusses the results. Finally, Chapter 6 summarizes the thesis contributions and provides an outlook on future research.\cite{NOT FINAL}

