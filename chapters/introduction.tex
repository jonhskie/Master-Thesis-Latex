\chapter{Introduction} \label{chap:introduction}

Robotic and Autonomous Systems (RAS) combine multiple disciplines, including control engineering and robotics, mechanical engineering, electronics, and software engineering.  Testing these systems is not as straightforward as using traditional methods and they require more because they span multiple disciplines. For researchers and engineers specializing in software testing, adapting existing techniques for RAS presents a significant challenge. This is why there is extensive literature dedicated to proposing and evaluating different testing techniques and processes, showing how esential it is to establish structured methods for ensuring the reliability of these complex systems. \cite{AMV23}

This validation challenge highlights a fundamental tension between simulation-only testing and full-scale physical experimentation, which are the two established methods in robotics evaluation. Simulation is central to the robotic development, offering a way to test control logic and experiment with system configurations before committing them to hardware \cite{Hu05, Mic04}. Simulations are often easier to set up, less expensive, and can run faster than real-world tests, allowing for rapid design exploration and to get better grasp of complex algorithms \cite{Mic04, Dos17, BM18}. However, a gap between the virtual and physical worlds emerges when simulation models are abandoned during the implementation phase. Virtual models, by their nature, cannot perfectly represent every characteristic of a physical hardware, such as the exact effects of friction, sensor noise, or small differences in motors \cite{Hu05, BM18}. On the other hand, testing with real hardware provides the highest fidelity and allows for controls to be refined based on presence of all the unpredictable physics and variability, that simulations can’t replicate \cite{Hu05, Cas21}. But this approach has its own severe drawbacks. Conducting physical experiments can be resource-intensive and time-consuming and requires significant funds, manpower, and infrastructure \cite{Hu05, Dos17, Mic04}. Furthermore, some critical scenarios, such as emergencies, are too dangerous to be recreated in the physical world \cite{Hu05}. For complex, large cooperative systems, testing the entire system with only real components may not even be feasible due to the issues of complexity and scale \cite{Hu05}. Since neither approach on its own is sufficient, there is a need for an intermediate solution that can connect the simulation with real-world experimentation \cite{Hu05}.

Hybrid methods such as Hardware-in-the-Loop Simulation (HILS) have emerged to bridge the validation gap by replacing segments of pure simulations with actual hardware components \cite{Hu05}. This research focuses on a specific application of this concept known as "robot-in-the-loop" (RitL) simulation, a more recent approach that allows physical robots and digital robot models to work together for comprehensive system testing and evaluation \cite{Hu05}. RitL allows researchers to work with actual robots inside a simulated environment, even when a full physical setup is unavailable\cite{Hu05}. Central to this approach is the Digital Twin \cite{AA23}. The digital twin is a live, virtual replica of a physical robot, that tracks its real-world counterpart in real time\cite{AA23}. With continues connection and rapid data exchange, the digital twin duplicates the robot’s actions, ensuring both remain in sync \cite{AA23}. To manage this hybrid test environment, Augmented Reality (AR) is increasingly utilized as a way for interaction and information exchange with autonomous systems, enhancing the efficiency of Human-Robot Interaction (HRI) \cite{MV20}. The combination of RitL testing \cite{Hu05}, synchronized Digital Twins \cite{AA23}, and AR interfaces \cite{MV20} paves the way for development and validation of future robotic systems.

The “Virtual Environment for mobile Robotic Applications” (VERA) framework integrates digital twins, AR, and vehicle-in-the-loop testing together into one system. \cite{Geh24}. VERA provides a modular platform for creating, managing, and visualizing synchronized virtual environments, which are presented both in simulations and as real-world projections \cite{Geh24}. This master's thesis builds directly upon the foundation laid by this original framework.

The VERA framework provides a good foundation, but its initial version has several limitations that this thesis seeks to address \cite{Geh24}. Firstly, the custom environment manager does not feature a full physics simulation, with the integration of enhanced physics noted as a direction for future work \cite{Geh24}. The 2D visualizer, that is created with Pygame, faced performance problems while handling a higher number of dynamic objects \cite{Geh24}. If there are too many simultaneous updates, its capacity was exceeded which lead to delayed and incomplete visualizations \cite{Geh24}. Additionally, while the framework supports AR projections, a more immersive Virtual Reality (VR) interaction was not implemented and was identified as a potential future work\cite{Geh24}. Therefore, the main problem is that although VERA’s concepts are promising, its custom components have technical constraints that limit it, particularly regarding physical realism, scalability, and user interaction.\cite{Geh24}.

To address these technical constraints, the primary objective of this thesis is to replace the custom simulation and visualization components of the VERA framework \cite{Geh24} with the Unity Engine \cite{Uni23}. This implementation will leverage the Unity Engine \cite{Uni23}, which was selected specifically for its advanced graphics, integrated physics, and native VR support, to overcome the previously identified constraints of the VERA system.

The core goal is to establish a high-fidelity, real-time digital twin \cite{AA23} of the EMAROS robot \cite{Geh24}, incorporating not only its model but also its live sensor data and physical properties, such as mass, inertia, and collision models. This digital twin will serve as the foundation for "robot-in-the-loop" \cite{Hu05} testing scenarios. Furthermore, this project will implement user interaction, moving beyond the original AR projections \cite{Geh24} to include Virtual Reality (VR) \cite{EM21} and desktop interfaces for scenario modification, robot control, and data visualization. This also includes reimplementing and enhancing VERA's AR floor projection feature by utilizing Unity's advanced rendering tools to improve visual quality and system capabilities \cite{Uni23}.

\cite{NOT FINAL}The remainder of this thesis is structured as follows: Chapter 2 reviews the foundational concepts of Robot-in-the-Loop testing, Digital Twins, and Mixed Reality, and includes a detailed review of the original VERA framework. Chapter 3 defines the new system requirements based on VERA's limitations. Chapter 4 details the implementation of the new architecture, including the Unity/ROS 2 integration, the EMAROS digital twin and the implemented scenarios. Chapter 5 presents the evaluation and discusses the results. Finally, Chapter 6 summarizes the thesis contributions and provides an outlook on future research.\cite{NOT FINAL}

