\chapter{Requirements}
\label{ch:requirements}

This chapter establishes the functional and non-functional requirements for the Mixed Reality Environment. Designed as a validation tool for Robot-in-the-Loop (RitL) testing, the system shall bridge the gap between virtual simulation and physical reality. The requirements follow a hierarchical structure, covering the simulation engine capabilities, system architecture, and digital twin interfaces. Furthermore, distinct requirements are defined for the autonomous agents that will operate within this environment to validate the system.

\section{Simulation Engine Capabilities}
\label{sec:platform_reqs}

These requirements define the technical capabilities of the underlying simulation engine. The criteria provide a basis for the technology selection process in the implementation phase.

\begin{itemize}
    \item \textbf{FR-01: Visual Fidelity:} The simulation engine shall support rendering pipelines capable of generating image data representative of real-world lighting and material properties. This is required to provide realistic synthetic input for the computer vision algorithms of the robot.
    
    \item \textbf{FR-02: Physics Simulation:} To overcome limitations in the previous VERA framework, the engine shall provide a physics system capable of resolving mass, friction, collision, and drag. This is necessary to simulate physical interactions, such as the robot pushing obstacles.
    
    \item \textbf{FR-03: XR Support:} The platform shall offer a mature framework for Virtual Reality (VR) and Augmented Reality (AR). It shall support the integration of output and input devices and project 3D content onto physical surfaces without requiring the development of custom drivers.
\end{itemize}

\section{System Architecture \& Middleware}
\label{sec:architecture_reqs}

The system architecture is defined by the constraints of the hardware and the need for standardized robotic communication.

\begin{itemize}
    \item \textbf{FR-04: Middleware Integration:} The system shall utilize ROS~2 as the exclusive middleware for all external communication. It shall function as a first-party participant in the network to minimize latency and shall use standard message definitions for all sensor streams, telemetry, and control commands. This ensures interoperability with the physical robot.
    
    \item \textbf{FR-05: Time Synchronization:} The system shall act as the simulation time source by publishing a clock signal. To prevent data drift in control algorithms, all simulated sensors and publishers shall synchronize their timestamps to this source.
    
    \item \textbf{FR-06: Scenario Management:} The system shall provide a mechanism to dynamically load and unload simulation environments via a network command during runtime. This capability is required to execute automated test suites across different environments without restarting the application.
\end{itemize}

\section{Digital Twin Interfaces}
\label{sec:digital_twin_reqs}

The system shall provide a digital representation of the robotic platform that mirrors its physical counterpart. This includes synchronization with real-world tracking, kinematic simulation, and the publishing of coordinate transforms.

\begin{itemize}
    \item \textbf{FR-07: Pose Synchronization:} The system shall accept real-time pose updates from an external tracking system to synchronize the position and orientation of the Digital Twin with the physical robot.
    
    \item \textbf{FR-08: Tracking Failsafe:} The system shall implement a failsafe that halts pose updates if the tracking data stream is interrupted for a defined threshold, preventing erratic behavior due to signal loss.

    \item \textbf{FR-09: Standalone Mode:} The system shall be capable of mimicking the kinematic behavior of the robot in the absence of physical hardware. It shall accept velocity commands and publish resulting odometry to validate navigation algorithms in a fully virtual setting.
    
    \item \textbf{FR-10: Coordinate Transforms:} The system shall publish dynamic coordinate transforms (TF) representing the robot's motion. It shall also support the configuration of static sensor offsets to match the physical mounting positions.
\end{itemize}

\section{Environment Capabilities}
\label{sec:environment_reqs}

These requirements define the capabilities of the virtual environment itself. This includes the generation of synthetic perception data and the mechanisms for dynamic interaction and visualization.

\begin{itemize}

    \item \textbf{FR-11: Sensor Simulation:} The system shall provide simulated sensors capable of generating synthetic perception data, including video feeds and ranging data. The sensors shall be capable of detecting both static environment structures and dynamic obstacles.
    
    \item \textbf{FR-12: Command Interface:} The system shall provide a generic network interface to receive commands and return status feedback, enabling the robot to trigger arbitrary simulation events.
    
    \item \textbf{FR-13: Dynamic Environment Interaction:} The system shall enable dynamic manipulation of the environment. This includes the physical actuation of objects (pushing/attaching), the modification of logical object states (e.g., property changes based on triggers), and the alteration of environmental surface properties during runtime.
    
    \item \textbf{FR-14: Telemetry Display:} The system shall render real-time robot status data (e.g., battery level, velocity, system load) as floating UI elements attached to the Digital Twin within the 3D environment.
\end{itemize}

\section{User Interface \& Mixed Reality}
\label{sec:ui_reqs}

These requirements define how human operators visualize and interact with the system.

\begin{itemize}
    \item \textbf{FR-15: AR Projection:} The system shall render a top-down, orthographic view of the scene. The projection parameters shall be configurable to align the virtual view 1:1 with the physical dimensions of the testbed floor.
    
    \item \textbf{FR-16: VR Interface:} The system shall provide a Virtual Reality mode, allowing users to view the Digital Twin in 3D space. Information interfaces shall automatically orient themselves (billboarding) to remain readable from the user's perspective.
        
    \item \textbf{FR-17: Goal Setting:} The interface shall allow users to set navigation targets compatible with standard navigation stacks by pointing at the virtual ground using a mouse or VR controller.
    
    \item \textbf{FR-18: Visualization Control:} The user interface shall allow runtime modification of the visual environment, including toggling the visibility of simulation layers and selecting active sensor visualizations.
\end{itemize}

\section{Autonomous Agent Requirements}
\label{sec:agent_reqs}

These requirements apply to the autonomous agents developed to interact with the environment. These agents serve to validate the system's capabilities and test the robot's responses to dynamic scenarios.

\begin{itemize}
    \item \textbf{FR-19: Sensor Dependence:} The autonomous agents shall make decisions based solely on environmental data provided through simulated sensors. They shall not access the internal state of the simulation engine to derive information.
    
    \item \textbf{FR-20: Perception Compatibility:} The agents shall utilize computer vision or perception algorithms capable of operating interchangeably on either synthetic simulation data or physical camera feeds.
          
    \item \textbf{FR-21: Closed-Loop Control:} The agents shall utilize standard robotic communication patterns to send action commands and monitor feedback topics to confirm task completion.
    
    \item \textbf{FR-22: Reactive Behavior:} The system shall support agents capable of reacting to the robot's movements in real-time, enabling the creation of dynamic entities that function as adversaries or collaborators.
\end{itemize}

\section{Non-Functional Requirements}
\label{sec:nfr}

The following constraints define the standards necessary to ensure reliability and extensibility.

\begin{itemize}
    \item \textbf{NFR-01: Low Latency:} The system shall minimize the delay between the reception of a state update and the rendering of the corresponding visual frame. Latency shall remain lower than the simulation frame time to ensure immediate visual feedback.
  
    \item \textbf{NFR-02: Frame Rate:} The simulation shall maintain a stable target frame rate (minimum 60 FPS) to prevent simulator sickness in VR and to ensure AR projections remain temporally consistent.    
       
    \item \textbf{NFR-03: Modularity:} The system architecture shall be modular, allowing individual components (e.g., sensor models, environment logic) to be added or modified without altering the core application.
    
    \item \textbf{NFR-04: Scalability:} The system shall support scenes with a high density of dynamic objects without violating frame rate stability requirements.
    
    \item \textbf{NFR-05: Configurability:} The system shall provide external interfaces to configure robot parameters, sensor properties, and environment settings, enabling adaptation to different physical setups without code recompilation.
\end{itemize}